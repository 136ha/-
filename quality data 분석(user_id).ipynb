{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기초작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import gc\n",
    "import random\n",
    "import lightgbm as lgb\n",
    "import re\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "PATH = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_qua = pd.read_csv(PATH+'train_quality_data.csv', thousands = ',')\n",
    "train_prob = pd.read_csv(PATH+'train_problem_data.csv')\n",
    "\n",
    "train_qua = train_qua.drop(['quality_3', 'quality_4'], axis=1)\n",
    "train_qua = train_qua.drop_duplicates()\n",
    "train_qua = train_qua.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "\n",
    "# transformer = RobustScaler().fit(train_qua.iloc[:, 3:14])\n",
    "# train_qua.iloc[:, 3:14] = transformer.transform(train_qua.iloc[:, 3:14])\n",
    "train_qua['quality_sum'] = train_qua.iloc[:, 3:14].sum()\n",
    "train_qua['quality_mean'] = train_qua.iloc[:, 3:14].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## quality 데이터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de27c74f858c49a8b53a10e71cda1d1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8281 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(15000, 2612, 13)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = np.zeros((15000,2612,13))\n",
    "\n",
    "for idx in tqdm(train_qua['user_id'].unique()):\n",
    "    train[idx-10000] = np.vstack((np.array(train_qua[train_qua['user_id']==idx].iloc[:, 3:16]), np.zeros((2612-train_qua[train_qua['user_id']==idx].shape[0],13))))\n",
    "\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_ui = np.zeros(15000)\n",
    "quality_ui[train_qua.user_id.unique()-10000] = 1\n",
    "quality_ui = quality_ui.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 27)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quality_str = np.hstack([np.max(train, axis=1) - np.min(train, axis=1),\n",
    "                         np.mean(train, axis=1), quality_ui])\n",
    "quality_str.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## problem 데이터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000,)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_prob = pd.read_csv(PATH+'train_problem_data.csv')\n",
    "problem = np.zeros(15000)\n",
    "# error와 동일한 방법으로 person_idx - 10000 위치에 \n",
    "# person_idx의 problem이 한 번이라도 발생했다면 1\n",
    "# 없다면 0\n",
    "problem[train_prob.user_id.unique()-10000] = 1 \n",
    "problem.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 27)\n",
      "(15000,)\n"
     ]
    }
   ],
   "source": [
    "train_x = quality_str\n",
    "train_y = problem\n",
    "del quality_str, problem\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4000, number of negative: 8000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001360 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2690\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 27\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.609975\tvalid_0's pr_auc: 0.475709\n",
      "==========================================================\n",
      "[LightGBM] [Info] Number of positive: 4000, number of negative: 8000\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000498 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2715\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 27\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's auc: 0.607272\tvalid_0's pr_auc: 0.47128\n",
      "==========================================================\n",
      "[LightGBM] [Info] Number of positive: 4000, number of negative: 8000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001198 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2693\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 27\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.595806\tvalid_0's pr_auc: 0.460078\n",
      "==========================================================\n",
      "[LightGBM] [Info] Number of positive: 4000, number of negative: 8000\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000461 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 27\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.600113\tvalid_0's pr_auc: 0.45591\n",
      "==========================================================\n",
      "[LightGBM] [Info] Number of positive: 4000, number of negative: 8000\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000511 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2694\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 27\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.58489\tvalid_0's pr_auc: 0.452758\n",
      "==========================================================\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "#-------------------------------------------------------------------------------------\n",
    "# validation auc score를 확인하기 위해 정의\n",
    "def f_pr_auc(probas_pred, y_true):\n",
    "    labels=y_true.get_label()\n",
    "    p, r, _ = precision_recall_curve(labels, probas_pred)\n",
    "    score=auc(r,p) \n",
    "    return \"pr_auc\", score, True\n",
    "#-------------------------------------------------------------------------------------\n",
    "models     = []\n",
    "recalls    = []\n",
    "precisions = []\n",
    "auc_scores   = []\n",
    "threshold = 0.5\n",
    "# 파라미터 설정\n",
    "params =      {\n",
    "                'boosting_type' : 'gbdt',\n",
    "                'objective'     : 'binary',\n",
    "                'metric'        : 'auc',\n",
    "                'seed': 1015\n",
    "                }\n",
    "#-------------------------------------------------------------------------------------\n",
    "# 5 Kfold cross validation\n",
    "k_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for train_idx, val_idx in k_fold.split(train_x, train_y):\n",
    "\n",
    "    # split train, validation set\n",
    "    X = train_x[train_idx]\n",
    "    y = train_y[train_idx]\n",
    "    valid_x = train_x[val_idx]\n",
    "    valid_y = train_y[val_idx]\n",
    "\n",
    "    d_train= lgb.Dataset(X, y)\n",
    "    d_val  = lgb.Dataset(valid_x, valid_y)\n",
    "    \n",
    "    #run traning\n",
    "    model = lgb.train(\n",
    "                        params,\n",
    "                        train_set       = d_train,\n",
    "                        num_boost_round = 1000,\n",
    "                        valid_sets      = d_val,\n",
    "                        feval           = f_pr_auc,\n",
    "                        verbose_eval    = 20, \n",
    "                        early_stopping_rounds = 3\n",
    "                       )\n",
    "    \n",
    "    # cal valid prediction\n",
    "    valid_prob = model.predict(valid_x)\n",
    "    valid_pred = np.where(valid_prob > threshold, 1, 0)\n",
    "    \n",
    "    # cal scores\n",
    "    recall    = recall_score(    valid_y, valid_pred)\n",
    "    precision = precision_score( valid_y, valid_pred)\n",
    "    auc_score = roc_auc_score(   valid_y, valid_prob)\n",
    "\n",
    "    # append scores\n",
    "    models.append(model)\n",
    "    recalls.append(recall)\n",
    "    precisions.append(precision)\n",
    "    auc_scores.append(auc_score)\n",
    "\n",
    "    print('==========================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5996113\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
